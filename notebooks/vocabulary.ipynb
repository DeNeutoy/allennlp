{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Vocabularies in AllenNLP\n",
    "A Vocabulary maps strings to integers, allowing for strings to be mapped to an\n",
    " out-of-vocabulary token.\n",
    "\n",
    "Vocabularies can be fit to a particular dataset, which we use to decide which tokens are\n",
    " in-vocabulary, or alternatively, they can be loaded directly from a static vocabulary file.\n",
    "\n",
    "\n",
    "First, let's import the vocabulary class from `allennlp` and create a vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an empty `Vocabulary` so we can look at the arguments it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = Vocabulary(counter=None, min_count=1, max_vocab_size=100000, non_padded_namespaces=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary takes 4 arguments: \n",
    "\n",
    "- A counter, which is a `Dict[str, Dict[str, int]]`: This is a nested dictionary because the allennlp Vocabulary class supports the idea of \"namespaces\". A namespace is a vocabulary which is associated with a part of your data. For instance, in a sequence tagging model, you would typically have two namespaces: A namespace of words for your textual input and a namespace of tags(e.g. \"NP\", \"VP\", etc) for your labels. This counter is therefore a mapping from string namespaces to dictionaries of `Dict[tokens -> counts]`.\n",
    "\n",
    "\n",
    "- A minimum count: Tokens with smaller counts than this won't be included in your `Vocabulary`.\n",
    "\n",
    "\n",
    "- A maximum vocab size: The lowest frequency words will be dropped to make your vocabulary this size.\n",
    "\n",
    "\n",
    "- Non padded namespaces: For some namespaces, such as words, we provide additional tokens commonly used in NLP applications - specifically, \"@@@PADDING@@@\" and \"@@@UNKNOWN@@@\". Why did we use these weird tokens we hear you ask? Well, if anything goes wrong in your model, it's going to be pretty obvious, because these tokens are pretty hard to miss. However, for other namespaces, such as tags, you _don't_ want these extra tokens, because in your model, you are going to be creating a distribution over the size of this namespace, so if we have added extra tags, your model could predict these. Naturally, we don't want this to happen, so we provide some reasonable defaults: any vocabulary namespace ending with `tag` or `label` won't have these extra tokens by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to interact with the vocabulary we just created. Let's add some words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add_token_to_namespace(\"Paul\", namespace=\"tokens\")\n",
    "vocab.add_token_to_namespace(\"Allen\", namespace=\"tokens\")\n",
    "\n",
    "vocab.add_token_to_namespace(\"PERSON\", namespace=\"tags\")\n",
    "vocab.add_token_to_namespace(\"PLACE\", namespace=\"tags\")\n",
    "print(vocab.get_index_to_token_vocabulary(\"tokens\"))\n",
    "print(vocab.get_index_to_token_vocabulary(\"tags\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}